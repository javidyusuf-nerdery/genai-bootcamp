{
  "cells": [
    {
      "cell_type": "code",
      "id": "Q6ozQVWGSMFJEoi1W8lLfMHV",
      "metadata": {
        "tags": [],
        "id": "Q6ozQVWGSMFJEoi1W8lLfMHV"
      },
      "source": [
        "## Step 1: Install Dependencies\n",
        "\n",
        "!pip install --upgrade --quiet \"google-cloud-aiplatform\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2: Configuration & Initialization\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "import re\n",
        "import os\n",
        "import unittest\n",
        "\n",
        "PROJECT_ID = \"qwiklabs-gcp-03-c72749959822\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Initialize Vertex AI\n",
        "try:\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "    print(f\"‚úÖ Vertex AI initialized for project: {PROJECT_ID}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing Vertex AI: {e}\")\n",
        "\n",
        "# Set an environment variable for our test class to read\n",
        "os.environ[\"GCP_PROJECT_ID\"] = PROJECT_ID"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9c6cTvdPptb",
        "outputId": "86e5df6d-c6a0-4704-fd5b-4a025e0a9b4d"
      },
      "id": "p9c6cTvdPptb",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Vertex AI initialized for project: qwiklabs-gcp-03-c72749959822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3: Define Classification function - build prompt using Gemini as the classifier\n",
        "\n",
        "def classify_question_with_gemini(user_question: str) -> str:\n",
        "    \"\"\"\n",
        "    (Production) Classifies a user question into one of four categories.\n",
        "    \"\"\"\n",
        "    categories = [\"Employment\", \"General Information\", \"Emergency Services\", \"Tax Related\"]\n",
        "    prompt = f\"\"\"\n",
        "    You are a text classification assistant. Your task is to classify the user's question\n",
        "    into one of the following categories:\n",
        "    - Employment\n",
        "    - General Information\n",
        "    - Emergency Services\n",
        "    - Tax Related\n",
        "    Respond with *only* the category name and nothing else.\n",
        "    User Question:\n",
        "    \"{user_question}\"\n",
        "    Category:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        category = response.text.strip()\n",
        "        if category in categories:\n",
        "            return category\n",
        "        else:\n",
        "            return \"General Information\" # Fallback\n",
        "    except Exception as e:\n",
        "        print(f\"Error during classification: {e}\")\n",
        "        return \"General Information\""
      ],
      "metadata": {
        "id": "8kS0T6Y3SDh-"
      },
      "id": "8kS0T6Y3SDh-",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4: Define Generate Social Media Post function with instructions to return creative text for posts\n",
        "\n",
        "def generate_social_media_post(topic: str, platform: str) -> str:\n",
        "    \"\"\"\n",
        "    (Production) Generates a government social media post.\n",
        "    \"\"\"\n",
        "    constraints = \"The post must be under 280 characters.\" if platform.lower() == \"twitter\" else \"The post can be 2-3 short paragraphs.\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a social media manager for a local government agency.\n",
        "    Target Platform: {platform}\n",
        "    Announcement Topic: \"{topic}\"\n",
        "    Instructions:\n",
        "    1.  Tone is authoritative, yet calm.\n",
        "    2.  Use 1-3 relevant emojis.\n",
        "    3.  Include 2-3 relevant hashtags.\n",
        "    4.  Constraint: {constraints}\n",
        "    5.  Respond with *only* the post content.\n",
        "    Post:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        post = response.text.strip()\n",
        "        return re.sub(r'^[\"\\']|[\"\\']$', '', post)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during post generation: {e}\")\n",
        "        return \"Error: Could not generate post.\""
      ],
      "metadata": {
        "id": "y02f4q3PSGxU"
      },
      "id": "y02f4q3PSGxU",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 5: Define the Unit Test class to build test cases\n",
        "\n",
        "# Check if the project ID is set, otherwise skip the tests\n",
        "PROJECT_ID_SET = \"GCP_PROJECT_ID\" in os.environ and os.environ[\"GCP_PROJECT_ID\"] != \"your-gcp-project-id\"\n",
        "\n",
        "@unittest.skipUnless(PROJECT_ID_SET, \"GCP_PROJECT_ID not set in Cell 2. Skipping tests.\")\n",
        "class TestProductionFunctions(unittest.TestCase):\n",
        "\n",
        "    def print_test_name(self):\n",
        "        \"\"\"Helper function to print the test name.\"\"\"\n",
        "        print(f\"\\n--- RUNNING: {self._testMethodName} ---\")\n",
        "\n",
        "    def test_classify_employment(self):\n",
        "        self.print_test_name()\n",
        "        result = classify_question_with_gemini(\"I need help finding a new job\")\n",
        "        self.assertEqual(result, \"Employment\")\n",
        "\n",
        "    def test_classify_tax(self):\n",
        "        self.print_test_name()\n",
        "        result = classify_question_with_gemini(\"How do I file my 1040?\")\n",
        "        self.assertEqual(result, \"Tax Related\")\n",
        "\n",
        "    def test_classify_emergency(self):\n",
        "        self.print_test_name()\n",
        "        result = classify_question_with_gemini(\"My house is on fire, please help!\")\n",
        "        self.assertEqual(result, \"Emergency Services\")\n",
        "\n",
        "    def test_generate_post_twitter(self):\n",
        "        self.print_test_name()\n",
        "        topic = \"All schools closed tomorrow due to heavy snow\"\n",
        "        post = generate_social_media_post(topic, \"Twitter\")\n",
        "        print(f\"Generated Post:\\n{post}\")\n",
        "\n",
        "        self.assertIn(\"#\", post)\n",
        "        self.assertIn(\"school\", post.lower())\n",
        "        self.assertLessEqual(len(post), 300) # 280 + buffer"
      ],
      "metadata": {
        "id": "0qSgpIlmSKd8"
      },
      "id": "0qSgpIlmSKd8",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 6: Run Unit Tests\n",
        "\n",
        "# We use verbosity=2 to get detailed output for each test\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False, verbosity=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTJFpmjjSOxW",
        "outputId": "7a21a1d6-67ed-430c-d76d-a03871dab6d3"
      },
      "id": "eTJFpmjjSOxW",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_classify_emergency (__main__.TestProductionFunctions.test_classify_emergency) ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RUNNING: test_classify_emergency ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ok\n",
            "test_classify_employment (__main__.TestProductionFunctions.test_classify_employment) ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RUNNING: test_classify_employment ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ok\n",
            "test_classify_tax (__main__.TestProductionFunctions.test_classify_tax) ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RUNNING: test_classify_tax ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ok\n",
            "test_generate_post_twitter (__main__.TestProductionFunctions.test_generate_post_twitter) ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RUNNING: test_generate_post_twitter ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 6.593s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Post:\n",
            "PUBLIC ANNOUNCEMENT: All schools will be CLOSED tomorrow due to heavy snow. Please prioritize safety & stay warm. üå®Ô∏è‚ùÑÔ∏è #SchoolClosures #SnowDay #WinterWeather\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 7: Define Prompts to evaluate against using original prompts (V1) and new prompts (V2)\n",
        "\n",
        "# --- V1 FUNCTIONS (Your Originals) ---\n",
        "\n",
        "def classify_question_v1(user_question: str) -> str:\n",
        "    # This is a copy of your function from Cell 3\n",
        "    return classify_question_with_gemini(user_question)\n",
        "\n",
        "def generate_post_v1(topic: str, platform: str) -> str:\n",
        "    # This is a copy of your function from Cell 4\n",
        "    return generate_social_media_post(topic, platform)\n",
        "\n",
        "# --- V2 FUNCTIONS (New Prompts to Test) ---\n",
        "\n",
        "def classify_question_v2(user_question: str) -> str:\n",
        "    \"\"\"V2: A shorter, more direct classification prompt.\"\"\"\n",
        "    categories = [\"Employment\", \"General Information\", \"Emergency Services\", \"Tax Related\"]\n",
        "\n",
        "    prompt = f\"\"\"Classify: \"{user_question}\"\n",
        "Categories: {', '.join(categories)}\n",
        "Category:\"\"\"\n",
        "\n",
        "    try:\n",
        "        model = GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        category = response.text.strip()\n",
        "        if category in categories:\n",
        "            return category\n",
        "        else:\n",
        "            return \"General Information\"\n",
        "    except Exception:\n",
        "        return \"General Information\"\n",
        "\n",
        "def generate_post_v2(topic: str, platform: str) -> str:\n",
        "    \"\"\"V2: A more 'engaging' tone for social media.\"\"\"\n",
        "    constraints = \"The post must be under 280 characters.\" if platform.lower() == \"twitter\" else \"The post can be 2-3 short paragraphs.\"\n",
        "    prompt = f\"\"\"\n",
        "    You are a witty, engaging social media manager for a local government.\n",
        "    Target Platform: {platform}\n",
        "    Announcement Topic: \"{topic}\"\n",
        "    Instructions:\n",
        "    1.  Tone is engaging and clear.\n",
        "    2.  Use emojis to make it friendly.\n",
        "    3.  Include 2-3 relevant hashtags.\n",
        "    4.  Constraint: {constraints}\n",
        "    5.  Respond with *only* the post content.\n",
        "    Post:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        model = GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        post = response.text.strip()\n",
        "        return re.sub(r'^[\"\\']|[\"\\']$', '', post)\n",
        "    except Exception:\n",
        "        return \"Error: Could not generate post.\"\n",
        "\n",
        "print(\"‚úÖ V1 and V2 functions for evaluation are now defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjsxL52ISW34",
        "outputId": "8e6bac92-9f16-4b64-b461-836bf8648787"
      },
      "id": "OjsxL52ISW34",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ V1 and V2 functions for evaluation are now defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Run Classification A/B Test, running both V1 and V2 functions and then comparing the results.\n",
        "\n",
        "print(\"--- üìä STARTING CLASSIFICATION A/B TEST ---\")\n",
        "\n",
        "# 1. Create your \"golden dataset\" for classification\n",
        "classification_dataset = [\n",
        "    {\"user_question\": \"I need help finding a new job\", \"ground_truth\": \"Employment\"},\n",
        "    {\"user_question\": \"How do I file my 1040?\", \"ground_truth\": \"Tax Related\"},\n",
        "    {\"user_question\": \"My house is on fire!\", \"ground_truth\": \"Emergency Services\"},\n",
        "    {\"user_question\": \"What's the capital of France?\", \"ground_truth\": \"General Information\"},\n",
        "]\n",
        "\n",
        "v1_correct = 0\n",
        "v2_correct = 0\n",
        "\n",
        "# 2. Loop over the dataset and test each prompt\n",
        "for item in classification_dataset:\n",
        "    question = item[\"user_question\"]\n",
        "    expected = item[\"ground_truth\"]\n",
        "\n",
        "    print(f\"\\nTesting Question: '{question}' (Expected: {expected})\")\n",
        "\n",
        "    # Test V1\n",
        "    v1_result = classify_question_v1(question)\n",
        "    print(f\"  V1 (Original) Result: {v1_result}\", end=\"\")\n",
        "    if v1_result == expected:\n",
        "        v1_correct += 1\n",
        "        print(\" (‚úÖ Correct)\")\n",
        "    else:\n",
        "        print(\" (‚ùå Incorrect)\")\n",
        "\n",
        "    # Test V2\n",
        "    v2_result = classify_question_v2(question)\n",
        "    print(f\"  V2 (Short) Result:    {v2_result}\", end=\"\")\n",
        "    if v2_result == expected:\n",
        "        v2_correct += 1\n",
        "        print(\" (‚úÖ Correct)\")\n",
        "    else:\n",
        "        print(\" (‚ùå Incorrect)\")\n",
        "\n",
        "# 3. Print the final scores\n",
        "print(\"\\n--- üèÅ FINAL CLASSIFICATION SCORES ---\")\n",
        "print(f\"V1 (Original) Score: {v1_correct} / {len(classification_dataset)}\")\n",
        "print(f\"V2 (Short) Score:    {v2_correct} / {len(classification_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnInUEStSb1J",
        "outputId": "7059cde2-cc65-4631-cdce-321c8559b3dc"
      },
      "id": "gnInUEStSb1J",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- üìä STARTING CLASSIFICATION A/B TEST ---\n",
            "\n",
            "Testing Question: 'I need help finding a new job' (Expected: Employment)\n",
            "  V1 (Original) Result: Employment (‚úÖ Correct)\n",
            "  V2 (Short) Result:    Employment (‚úÖ Correct)\n",
            "\n",
            "Testing Question: 'How do I file my 1040?' (Expected: Tax Related)\n",
            "  V1 (Original) Result: Tax Related (‚úÖ Correct)\n",
            "  V2 (Short) Result:    Tax Related (‚úÖ Correct)\n",
            "\n",
            "Testing Question: 'My house is on fire!' (Expected: Emergency Services)\n",
            "  V1 (Original) Result: Emergency Services (‚úÖ Correct)\n",
            "  V2 (Short) Result:    Emergency Services (‚úÖ Correct)\n",
            "\n",
            "Testing Question: 'What's the capital of France?' (Expected: General Information)\n",
            "  V1 (Original) Result: General Information (‚úÖ Correct)\n",
            "  V2 (Short) Result:    General Information (‚úÖ Correct)\n",
            "\n",
            "--- üèÅ FINAL CLASSIFICATION SCORES ---\n",
            "V1 (Original) Score: 4 / 4\n",
            "V2 (Short) Score:    4 / 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 9: Run Generation A/B test, showing each created post side by side with different tones.\n",
        "\n",
        "print(\"--- üìä STARTING GENERATION A/B TEST ---\")\n",
        "\n",
        "# 1. Create your dataset for generation\n",
        "generation_dataset = [\n",
        "    {\"topic\": \"All schools closed tomorrow due to heavy snow\", \"platform\": \"Twitter\"},\n",
        "    {\"topic\": \"City Hall is closed Monday for the holiday\", \"platform\": \"Facebook\"},\n",
        "    {\"topic\": \"Flash flood warning for downtown\", \"platform\": \"Twitter\"},\n",
        "]\n",
        "\n",
        "# 2. Loop and print results side-by-side\n",
        "for i, item in enumerate(generation_dataset):\n",
        "    print(f\"\\n--- TEST {i+1}: {item['topic']} ({item['platform']}) ---\")\n",
        "\n",
        "    # Test V1\n",
        "    print(\"\\n  --- V1 (Authoritative) Post ---\")\n",
        "    v1_post = generate_post_v1(topic=item[\"topic\"], platform=item[\"platform\"])\n",
        "    print(v1_post)\n",
        "\n",
        "    # Test V2\n",
        "    print(\"\\n  --- V2 (Engaging) Post ---\")\n",
        "    v2_post = generate_post_v2(topic=item[\"topic\"], platform=item[\"platform\"])\n",
        "    print(v2_post)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "print(\"\\n--- üèÅ GENERATION TEST COMPLETE ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0YPyDdXSiRR",
        "outputId": "79c2e58a-b873-40da-c306-abec6b2a7e28"
      },
      "id": "z0YPyDdXSiRR",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- üìä STARTING GENERATION A/B TEST ---\n",
            "\n",
            "--- TEST 1: All schools closed tomorrow due to heavy snow (Twitter) ---\n",
            "\n",
            "  --- V1 (Authoritative) Post ---\n",
            "ATTENTION: All schools will be closed tomorrow, [Date], due to heavy snow and hazardous travel conditions. Your safety is our priority. Stay warm! ‚ùÑÔ∏èüå®Ô∏è #SchoolClosures #SnowDay\n",
            "\n",
            "  --- V2 (Engaging) Post ---\n",
            "Snow much fun coming! ‚ùÑÔ∏èüå®Ô∏è All local schools will be CLOSED tomorrow due to heavy snow. Time for cozy blankets & snow day adventures! Stay safe & warm, everyone. üòä #SnowDay #SchoolClosures #CommunityAlert\n",
            "---------------------------------\n",
            "\n",
            "--- TEST 2: City Hall is closed Monday for the holiday (Facebook) ---\n",
            "\n",
            "  --- V1 (Authoritative) Post ---\n",
            "Please be advised that City Hall will be closed on Monday, [Insert Date of Monday Here], in observance of the upcoming holiday. We want to ensure all residents are aware of this temporary closure to plan accordingly. üèõÔ∏è\n",
            "\n",
            "Normal business operations will resume promptly on Tuesday, [Insert Date of Tuesday Here], at our regular hours. We appreciate your understanding and cooperation during this time. We wish everyone a safe and restful holiday weekend. üìÖ\n",
            "\n",
            "#CityHallClosure #HolidayHours #PublicNotice\n",
            "\n",
            "  --- V2 (Engaging) Post ---\n",
            "Hey there, wonderful residents! üëã Just a friendly heads-up from your City Hall squad. This coming Monday, we'll be taking a little break to celebrate the holiday! ü•≥\n",
            "\n",
            "That means City Hall will be closed all day on Monday. We encourage you to plan ahead for any services you might need, or check out our website for online resources! We'll be back bright and early on Tuesday, ready to serve you.\n",
            "\n",
            "Wishing you all a fantastic long weekend! Stay safe and enjoy the holiday festivities. See you back here soon! ‚ú® #YourCity #HolidayHours #CityHall\n",
            "---------------------------------\n",
            "\n",
            "--- TEST 3: Flash flood warning for downtown (Twitter) ---\n",
            "\n",
            "  --- V1 (Authoritative) Post ---\n",
            "Flash Flood Warning issued for Downtown effective immediately. Seek higher ground if in low-lying areas. Do not drive through floodwaters. Stay safe and informed. ‚ö†Ô∏è‚òîÔ∏è #FlashFlood #DowntownSafety #WeatherAlert\n",
            "\n",
            "  --- V2 (Engaging) Post ---\n",
            "üö®üåßÔ∏è Downtowners, heads up! A Flash Flood Warning is in effect. Avoid flooded roads ‚Äì remember, 'Turn Around, Don't Drown!' Stay safe out there. We're watching the skies! #FlashFlood #Downtown #WeatherAlert\n",
            "---------------------------------\n",
            "\n",
            "--- üèÅ GENERATION TEST COMPLETE ---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-04-72bc0c4e8988 (Nov 12, 2025, 5:44:42‚ÄØPM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}