{
  "cells": [
    {
      "cell_type": "code",
      "id": "idIf7UI2UOgVxqpcWbEFjG3f",
      "metadata": {
        "tags": [],
        "id": "idIf7UI2UOgVxqpcWbEFjG3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "af530b99-faef-4add-9793-85384ec20b77"
      },
      "source": [
        "# 1. Install necessary libraries\n",
        "!pip install --upgrade google-cloud-aiplatform google-cloud-bigquery\n",
        "\n",
        "print(\"--- Libraries installed ---\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.12/dist-packages (1.127.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.38.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.25.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.1.2)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.37.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.41.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.11.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.32.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform) (1.7.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (4.11.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from shapely<3.0.0->google-cloud-aiplatform) (2.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.37.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "--- Libraries installed ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Import Libraries\n",
        "import sys\n",
        "import os\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "from google.cloud import bigquery\n",
        "\n",
        "print(\"--- Modules imported ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9fNpJvruFZx",
        "outputId": "cf438dd2-4cb4-4f27-f7a5-bc9a55812542"
      },
      "id": "u9fNpJvruFZx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform/models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.\n",
            "  from google.cloud.aiplatform.utils import gcs_utils\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Modules imported ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Configuration\n",
        "\n",
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"qwiklabs-gcp-03-c72749959822\"\n",
        "\n",
        "# The region for your Vertex AI and BigQuery resources\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# The full BigQuery table ID in the format: project.dataset.table\n",
        "TABLE_ID = \"qwiklabs-gcp-03-c72749959822.genai_bootcamp.aurora_bay_faqs_embedded\"\n",
        "\n",
        "# This MUST be the same model used to create your embeddings.\n",
        "# Common models: \"text-embedding-004\", \"textembedding-gecko@003\"\n",
        "EMBEDDING_MODEL_NAME = \"text-embedding-005\"\n",
        "\n",
        "# Model for generation\n",
        "LLM_MODEL_NAME = \"gemini-2.5-pro\"\n",
        "\n",
        "print(f\"--- Configuration set for project: {PROJECT_ID} ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6g6sOkauGjE",
        "outputId": "c5866bc5-7033-49d6-f2bc-7b753a6d333e"
      },
      "id": "K6g6sOkauGjE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Configuration set for project: qwiklabs-gcp-03-c72749959822 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Authenticate User\n",
        "# This block explicitly authenticates your user account in Colab.\n",
        "try:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "    print(\"--- Authentication successful ---\")\n",
        "except ImportError:\n",
        "    print(\"Not in a Colab environment, assuming default credentials.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCloKuwAuHtW",
        "outputId": "8141af64-ea4a-49d3-df30-d725be560364"
      },
      "id": "PCloKuwAuHtW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: google.colab.auth.authenticate_user() is not supported in Colab Enterprise.\n",
            "--- Authentication successful ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Initialize Vertex AI and BigQuery Clients\n",
        "# We wrap this in a try/except block to catch initialization errors\n",
        "print(\"Initializing Vertex AI and BigQuery clients...\")\n",
        "try:\n",
        "    vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "    # Authenticate BQ PROJECT_ID\n",
        "    bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "    embedding_model = TextEmbeddingModel.from_pretrained(EMBEDDING_MODEL_NAME)\n",
        "    llm = GenerativeModel(LLM_MODEL_NAME)\n",
        "\n",
        "    print(\"âœ… Clients initialized successfully.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ðŸš¨ ERROR: Failed to initialize clients. See details below.\")\n",
        "    print(f\"Error message: {e}\")\n",
        "    print(\"Please check your PROJECT_ID, LOCATION, and ensure APIs (Vertex AI, BigQuery) are enabled.\")\n",
        "    # Stop execution if clients fail\n",
        "    sys.exit(\"Client initialization failed. Please fix the error above and restart the kernel.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05FQXUCbuK3n",
        "outputId": "7ffcf8a1-348b-413d-a2bb-7f059af809f1"
      },
      "id": "05FQXUCbuK3n",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Vertex AI and BigQuery clients...\n",
            "âœ… Clients initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "/usr/local/lib/python3.12/dist-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Chatbot Function Definition\n",
        "\n",
        "def ask_chatbot(user_query: str, top_k: int = 3) -> str:\n",
        "    \"\"\"\n",
        "    Performs the full RAG pipeline:\n",
        "    1. Embeds the query.\n",
        "    2. Retrieves context from BigQuery using VECTOR_SEARCH.\n",
        "    3. Generates an answer using an LLM.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\nDEBUG: Embedding user query: '{user_query}'\")\n",
        "\n",
        "    # --- 1. RETRIEVE (Embed Query and Search BigQuery) ---\n",
        "    try:\n",
        "        # Generate embedding for the user's query\n",
        "        query_embedding = embedding_model.get_embeddings([user_query])[0].values\n",
        "\n",
        "        # Build the BigQuery VECTOR_SEARCH query\n",
        "        sql_query = f\"\"\"\n",
        "        SELECT\n",
        "            base.question,\n",
        "            base.answer,\n",
        "            base.content,\n",
        "            distance\n",
        "        FROM\n",
        "            VECTOR_SEARCH(\n",
        "                TABLE `{TABLE_ID}`,\n",
        "                'ml_generate_embedding_result',  -- The column with your embeddings\n",
        "                (SELECT {query_embedding} AS ml_generate_embedding_result),\n",
        "                top_k => {top_k},\n",
        "                distance_type => 'COSINE'\n",
        "            )\n",
        "        \"\"\"\n",
        "\n",
        "        # Execute the query\n",
        "        print(f\"DEBUG: Running BigQuery vector search...\")\n",
        "        query_job = bq_client.query(sql_query)\n",
        "        results = query_job.result()\n",
        "\n",
        "        # Format the retrieved data as context\n",
        "        context = \"\"\n",
        "        for row in results:\n",
        "            context += f\"Source Question: {row.question}\\nAnswer: {row.answer}\\nContent: {row.content}\\n---\\n\"\n",
        "\n",
        "        if not context:\n",
        "            print(\"DEBUG: No relevant documents found in BigQuery.\")\n",
        "            return \"I'm sorry, I couldn't find any relevant information to answer your question.\"\n",
        "\n",
        "        print(f\"DEBUG: Retrieved context:\\n{context}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ðŸš¨ ERROR during BigQuery vector search: {e}\")\n",
        "        return f\"Error during BigQuery vector search: {e}\"\n",
        "\n",
        "    # --- 2. GENERATE (Pass Context and Query to LLM) ---\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful assistant. Your task is to answer the user's question based *only*\n",
        "    on the provided context. If the context does not contain the answer,\n",
        "    state that you don't have that information.\n",
        "\n",
        "    **Provided Context:**\n",
        "    {context}\n",
        "\n",
        "    **User's Question:**\n",
        "    {user_query}\n",
        "\n",
        "    **Answer:**\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Generate the final answer\n",
        "        print(\"DEBUG: Generating answer with LLM...\")\n",
        "        response = llm.generate_content([Part.from_text(prompt)])\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"ðŸš¨ ERROR during answer generation: {e}\")\n",
        "        return f\"Error during answer generation: {e}\"\n",
        "\n",
        "print(\"--- Chatbot function defined. Ready to use. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-slkdA2uMI4",
        "outputId": "2d42ae3f-e45b-444c-ccba-225917015932"
      },
      "id": "o-slkdA2uMI4",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chatbot function defined. Ready to use. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Interactive Chat Loop\n",
        "print(\"\\n--- ðŸ¤– Chatbot is ready ---\")\n",
        "print(\"Ask a question. Type 'quit' to exit.\")\n",
        "\n",
        "while True:\n",
        "    # Get user input from the Colab prompt\n",
        "    user_question = input(\"\\nYour Question: \")\n",
        "\n",
        "    if user_question.lower() == 'quit':\n",
        "        print(\"\\nGoodbye!\")\n",
        "        break\n",
        "\n",
        "    # Get the chatbot's answer\n",
        "    response = ask_chatbot(user_question)\n",
        "\n",
        "    print(\"---------------------------------\")\n",
        "    print(f\"Chatbot: {response}\")\n",
        "    print(\"---------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alm-dvVIuNrb",
        "outputId": "da09ac6b-ee14-4d6a-9e0b-2f1faa32e513"
      },
      "id": "alm-dvVIuNrb",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ðŸ¤– Chatbot is ready ---\n",
            "Ask a question. Type 'quit' to exit.\n",
            "\n",
            "Your Question: What companies operate in Aurora Bay?\n",
            "\n",
            "DEBUG: Embedding user query: 'What companies operate in Aurora Bay?'\n",
            "DEBUG: Running BigQuery vector search...\n",
            "DEBUG: Retrieved context:\n",
            "Source Question: What are the primary industries in Aurora Bay?\n",
            "Answer: The primary industries include commercial fishing, tourism, and small-scale logging in the nearby forests.\n",
            "Content: What are the primary industries in Aurora Bay?The primary industries include commercial fishing, tourism, and small-scale logging in the nearby forests.\n",
            "---\n",
            "Source Question: What local outdoor adventure companies operate in Aurora Bay?\n",
            "Answer: North Star Excursions and Bay Explorers offer guided hikes, kayak tours, and wilderness camping experiences for visitors and residents.\n",
            "Content: What local outdoor adventure companies operate in Aurora Bay?North Star Excursions and Bay Explorers offer guided hikes, kayak tours, and wilderness camping experiences for visitors and residents.\n",
            "---\n",
            "Source Question: What is the population of Aurora Bay?\n",
            "Answer: Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces.\n",
            "Content: What is the population of Aurora Bay?Aurora Bay has a population of approximately 3,200 residents, although it can fluctuate seasonally due to temporary fishing and tourism workforces.\n",
            "---\n",
            "\n",
            "DEBUG: Generating answer with LLM...\n",
            "---------------------------------\n",
            "Chatbot: Based on the context provided, North Star Excursions and Bay Explorers are two local outdoor adventure companies that operate in Aurora Bay. They offer guided hikes, kayak tours, and wilderness camping experiences.\n",
            "---------------------------------\n",
            "\n",
            "Your Question: quit\n",
            "\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-04-72bc0c4e8988 (Nov 12, 2025, 3:18:25â€¯PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}